{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "char-rnn-generation-dickens-modifiedv2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "fSN3y6ojecAQ",
        "colab_type": "code",
        "outputId": "2ef0554b-e184-4e99-980a-589505b78b16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install unidecode"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (1.0.23)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gu60Pq-d5c-H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML\n",
        "\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "idd5CuKKt4p8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_RMdhSvKeLg0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Prepare data\n",
        "\n",
        "The file we are using is a plain text file. We turn any potential unicode characters into plain ASCII by using the `unidecode` package (which you can install via `pip` or `conda`)."
      ]
    },
    {
      "metadata": {
        "id": "oQ5m7-oVeLg3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import unidecode\n",
        "# import string\n",
        "# import random\n",
        "# import re\n",
        "\n",
        "# all_characters = string.printable\n",
        "# n_characters = len(all_characters)\n",
        "\n",
        "# file = unidecode.unidecode(open('all_story.txt').read())\n",
        "# file_len = len(file)\n",
        "# print('file_len =', file_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GdtuxB0judaA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def read_file(filename): \n",
        "  text = open(filename, 'r', encoding = \"utf-8-sig\").read().splitlines()\n",
        "  text = \" \".join(text)\n",
        "  return text\n",
        "\n",
        "import string\n",
        "import unicodedata\n",
        "\n",
        "#all_characters = string.ascii_letters + string.punctuation + string.digits + \" \"\n",
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "\n",
        "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "        and c in all_characters\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9djWkmhcvNL2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file = read_file(\"all_story.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iDAva8W0vbMo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file = unicodeToAscii(file)\n",
        "file_len = len(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uTmUUm98vTNf",
        "colab_type": "code",
        "outputId": "2f00caf4-1cf5-421a-cb78-51414f959ffc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "file_len"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23456194"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "URrn79EHeLhF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To make inputs out of this big string of data, we will be splitting it into chunks."
      ]
    },
    {
      "metadata": {
        "id": "4713a-K0eLhH",
        "colab_type": "code",
        "outputId": "4431af2e-e556-4328-ce32-d1fd5ae2a2cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "chunk_len = 1000\n",
        "\n",
        "def random_chunk():\n",
        "    start_index = random.randint(0, file_len - chunk_len)\n",
        "    end_index = start_index + chunk_len + 1\n",
        "    return file[start_index:end_index]\n",
        "\n",
        "print(random_chunk())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nd leave him in it; others, that he should be reduced to a state of temporary insensibility, by knocking on the head; others, that he should be sworn to sit where he was until to-morrow at the same hour; others again, that he should be gagged and taken off with them, under a sufficient guard. All these propositions being overruled, it was concluded, at last, to bind him in his chair, and the word was passed for Dennis.  Lookee here, Jack! said Hugh, striding up to him: We are going to tie you, hand and foot, but otherwise you wont be hurt. Dye hear?  John Willet looked at another man, as if he didnt know which was the speaker, and muttered something about an ordinary every Sunday at two oclock.  You wont be hurt I tell you, Jack--do you hear me? roared Hugh, impressing the assurance upon him by means of a heavy blow on the back. Hes so dead scared, hes woolgathering, I think. Give him a drop of something to drink here. Hand over, one of you.  A glass of liquor being passed forward, Hugh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1naM58zoeLhO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Build the Model\n",
        "\n",
        "This model will take as input the character for step $t_{-1}$ and is expected to output the next character $t$. There are three layers - one linear layer that encodes the input character into an internal state, one GRU layer (which may itself have multiple layers) that operates on that internal state and a hidden state, and a decoder layer that outputs the probability distribution."
      ]
    },
    {
      "metadata": {
        "id": "FKWI0NgXzDkq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class CharRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, n_layers=1, model =\"gru\"):\n",
        "        super(CharRNN, self).__init__()\n",
        "        self.model = str(model).lower()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "             \n",
        "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
        "        if self.model == \"gru\":\n",
        "            self.rnn = nn.GRU(hidden_size, hidden_size, n_layers, dropout = 0.5)\n",
        "        elif self.model == \"lstm\":\n",
        "            self.rnn = nn.LSTM(hidden_size, hidden_size, n_layers, dropout = 0.5)\n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "#     def forward(self, input, hidden):\n",
        "#         batch_size = input.size(0)\n",
        "#         encoded = self.encoder(input)\n",
        "#         output, hidden = self.rnn(encoded.view(1, batch_size, -1), hidden)\n",
        "#         output = self.decoder(output.view(batch_size, -1))\n",
        "#         return output, hidden\n",
        "\n",
        "    def forward(self, input, hidden, use_softmax=False):\n",
        "        batch_size = input.size(0)\n",
        "        encoded = self.encoder(input)\n",
        "        output, hidden = self.rnn(encoded.view(1, batch_size, -1), hidden)\n",
        "        output = output.contiguous().view(batch_size, hidden_size) \n",
        "        output = F.dropout(output, 0.5)\n",
        "        output = self.decoder(output).view(batch_size, -1)\n",
        "        return (F.softmax(output,dim=2), hidden) if use_softmax else (output, hidden)\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        if self.model == \"lstm\":\n",
        "            return (Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)),\n",
        "                    Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)))\n",
        "        return Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "96M7d1jvo-HW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b72cdd5-4281-4b9d-f7d1-e3d836c430c3"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "torch.manual_seed(42)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f9971d43390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "bk6-Z6LP19Ww",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tgpPNjYaeLhV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Inputs and Targets"
      ]
    },
    {
      "metadata": {
        "id": "iJO9p9qgeLhW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Each chunk will be turned into a tensor, specifically a `LongTensor` (used for integer values), by looping through the characters of the string and looking up the index of each character in `all_characters`."
      ]
    },
    {
      "metadata": {
        "id": "AQ_fnWGKeLhX",
        "colab_type": "code",
        "outputId": "218084eb-8586-475b-e649-1f1d939cad9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Turn string into list of longs\n",
        "def char_tensor(string):\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        tensor[c] = all_characters.index(string[c])\n",
        "    return Variable(tensor)\n",
        "\n",
        "print(char_tensor('abcDEF'))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([10, 11, 12, 39, 40, 41])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ISv-XmXteLhb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally we can assemble a pair of input and target tensors for training, from a random chunk. The input will be all characters *up to the last*, and the target will be all characters *from the first*. So if our chunk is \"abc\" the input will correspond to \"ab\" while the target is \"bc\"."
      ]
    },
    {
      "metadata": {
        "id": "njW2MYAP0Oky",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def random_training_set(chunk_len, batch_size):\n",
        "    inp = torch.LongTensor(batch_size, chunk_len)\n",
        "    target = torch.LongTensor(batch_size, chunk_len)\n",
        "    for bi in range(batch_size):\n",
        "        start_index = random.randint(0, file_len - chunk_len)\n",
        "        end_index = start_index + chunk_len + 1\n",
        "        chunk = file[start_index:end_index]\n",
        "        inp[bi] = char_tensor(chunk[:-1])\n",
        "        target[bi] = char_tensor(chunk[1:])\n",
        "    inp = Variable(inp)\n",
        "    target = Variable(target)\n",
        "    if device == \"cuda\":\n",
        "        inp = inp.cuda()\n",
        "        target = target.cuda()\n",
        "    return inp, target\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nnCTCaPNv100",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Split Test and Validation**"
      ]
    },
    {
      "metadata": {
        "id": "BB32fE0WvzH-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a1HKM7kseLhe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Evaluating\n",
        "\n",
        "To evaluate the network we will feed one character at a time, use the outputs of the network as a probability distribution for the next character, and repeat. To start generation we pass a priming string to start building up the hidden state, from which we then generate one character at a time."
      ]
    },
    {
      "metadata": {
        "id": "-VlOY7ad-mnL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate(decoder, prime_str='A', predict_len=100, temperature=0.8, cuda=device):\n",
        "    hidden = decoder.init_hidden(1)\n",
        "    prime_input = Variable(char_tensor(prime_str).unsqueeze(0))\n",
        "\n",
        "    if cuda == \"cuda\":\n",
        "      prime_input = prime_input.cuda()\n",
        "      if isinstance(hidden, tuple):\n",
        "        hidden = (hidden[0].cuda(), hidden[1].cuda())\n",
        "      else: \n",
        "        hidden = hidden.cuda()\n",
        "    predicted = prime_str\n",
        "\n",
        "    # Use priming string to \"build up\" hidden state\n",
        "    for p in range(len(prime_str) - 1):\n",
        "        _, hidden = decoder(prime_input[:,p], hidden)\n",
        "        \n",
        "    inp = prime_input[:,-1]\n",
        "    \n",
        "    for p in range(predict_len):\n",
        "        output, hidden = decoder(inp, hidden)\n",
        "        \n",
        "        # Sample from the network as a multinomial distribution\n",
        "        output_dist = output.data.view(-1).div(temperature).exp()\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "\n",
        "        # Add predicted character to string and use as next input\n",
        "        predicted_char = all_characters[top_i]\n",
        "        predicted += predicted_char\n",
        "        inp = Variable(char_tensor(predicted_char).unsqueeze(0))\n",
        "        if cuda:\n",
        "            inp = inp.cuda()\n",
        "\n",
        "    return predicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sKzO2VXreLhi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training"
      ]
    },
    {
      "metadata": {
        "id": "DK1wA7IkeLhj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A helper to print the amount of time passed:"
      ]
    },
    {
      "metadata": {
        "id": "WiGKkGFteLhk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time, math\n",
        "\n",
        "def time_since(since):\n",
        "    s = time.time() - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sNYD9ajieLhn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The main training function"
      ]
    },
    {
      "metadata": {
        "id": "IaS_zM9Q0I4s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(inp, target):\n",
        "    hidden = decoder.init_hidden(batch_size)\n",
        "    if device == \"cuda\":\n",
        "      if model == \"gru\": \n",
        "        hidden = hidden.cuda() \n",
        "      else:\n",
        "        hidden = (hidden[0].cuda(), hidden[1].cuda())\n",
        "    decoder.zero_grad()\n",
        "    loss = 0\n",
        "\n",
        "    for c in range(chunk_len):\n",
        "        output, hidden = decoder(inp[:,c], hidden)\n",
        "        loss += criterion(output.view(batch_size, -1), target[:,c])\n",
        "\n",
        "    loss.backward()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    #return loss.data[0] / chunk_len\n",
        "    return loss.item() / chunk_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IcQa2W030sPW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os \n",
        "def save():\n",
        "    save_filename = os.path.splitext(os.path.basename(filename))[0] + '.pt'\n",
        "    torch.save(decoder, save_filename)\n",
        "    print('Saved as %s' % save_filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xtZlbfJieLhr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then we define the training parameters, instantiate the model, and start training:"
      ]
    },
    {
      "metadata": {
        "id": "NfwHeBCR01mV",
        "colab_type": "code",
        "outputId": "b5b64326-12a9-4751-9d65-d4d453a52169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "cell_type": "code",
      "source": [
        "model = 'gru'\n",
        "n_epochs = 200\n",
        "hidden_size = 1000\n",
        "n_layers = 2\n",
        "learning_rate = 0.005\n",
        "chunk_len = 200\n",
        "batch_size = 512\n",
        "\n",
        "filename = \"char-rnn\"\n",
        "print_every = 100\n",
        "plot_every = 10\n",
        "\n",
        "decoder = CharRNN(n_characters, hidden_size, n_characters, n_layers, model)\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "if device == \"cuda\":\n",
        "    decoder.cuda()\n",
        "\n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0\n",
        "\n",
        "\n",
        "try:\n",
        "    print(\"Training for %d epochs...\" % n_epochs)\n",
        "    #for epoch in tqdm(range(1, n_epochs + 1)):\n",
        "    for epoch in range(1, n_epochs + 1): \n",
        "        loss = train(*random_training_set(chunk_len, batch_size))\n",
        "        loss_avg += loss\n",
        "\n",
        "#         if epoch % print_every == 0:\n",
        "#             print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
        "#             print(generate(decoder, 'Wh', 100, cuda=device), '\\n')\n",
        "            \n",
        "        if epoch % plot_every == 0:\n",
        "          all_losses.append(loss_avg / plot_every)\n",
        "          loss_avg = 0\n",
        "          clear_output(wait=True)\n",
        "          plt.plot(all_losses)\n",
        "          plt.pause(0.05)\n",
        "          print(\"number of epochs completed:\", epoch)\n",
        "          print(\"========== generated samples ==========\")\n",
        "          print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
        "          print(generate(decoder, 'Wh', 100, cuda=device), '\\n')\n",
        "\n",
        "    print(\"Saving...\")\n",
        "    save()\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Saving before quit...\")\n",
        "    save()\n",
        "    \n",
        "if epoch % plot_every == 0:\n",
        "        all_losses.append(loss_avg / plot_every)\n",
        "        loss_avg = 0"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6teFRShpEdMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "number of epochs completed: 200\n",
            "========== generated samples ==========\n",
            "[18m 8s (200 100%) 1.6319]\n",
            "Whink of the other accontinisuut; and at the Hinge, has not hose of behings, she oust heart of the str \n",
            "\n",
            "Saving...\n",
            "Saved as char-rnn.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type CharRNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "4Tzcu0GTeLhw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Plotting the Training Losses\n",
        "\n",
        "Plotting the historical loss from all_losses shows the network learning:"
      ]
    },
    {
      "metadata": {
        "id": "zrFP4NNZeLhx",
        "colab_type": "code",
        "outputId": "b8138366-e63e-4903-d570-31177e36af86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.ticker as ticker\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(all_losses)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f99701c26a0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAD4CAYAAAAuNhccAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nekYK0wAbZgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "NkZi0HNteLh1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Evaluating at different \"temperatures\"\n",
        "\n",
        "In the `evaluate` function above, every time a prediction is made the outputs are divided by the \"temperature\" argument passed. Using a higher number makes all actions more equally likely, and thus gives us \"more random\" outputs. Using a lower value (less than 1) makes high probabilities contribute more. As we turn the temperature towards zero we are choosing only the most likely outputs.\n",
        "\n",
        "We can see the effects of this by adjusting the `temperature` argument."
      ]
    },
    {
      "metadata": {
        "id": "nmFX1kWkeLh1",
        "colab_type": "code",
        "outputId": "4c682849-66d8-445e-f31a-bb8e629b8cff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "cell_type": "code",
      "source": [
        "start = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"]\n",
        "for i in start: \n",
        "  print(generate(decoder, i, predict_len=300, temperature=0.5, cuda=device))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "and replied the faction and to a present the blight and from him of said of his hand of the old gave should shoute, that the voice of his hands to the deliined the other face in a lintener had not be a neare and dray with the way of partical on one and and winder to him in the little when in a the ha\n",
            "beer the word of the croad best and recended to the tire.  I though you must said, and heaved to the last part of a look, resideral in a stare of the seared to a tands have been the poor of his fertainer in his laughter to me all the person of the Charces.  The great to the high object to her down in\n",
            "cart and than having presone of the cather of her looking on the starder in the such a commons alrious in the worth dear to all the did for a roard of a mistration, and starty looked of post on the from the cottable so calling into the door, a man of the complemen of his lead into the course was a gr\n",
            "din to destrace, and dood it of some of many partice to house and at the lams with a molent from it was not bether the didnt of the bull and for the tium on the street was as light that he appearing in it was a windows in a prent have had an one at little genlise in the wide she dries that he had bee\n",
            "e to have been as a  tomething of it speak when she was no, in a dear to you have she had been are in the some regardments of his all that I am and the dot of the sent of the dasting him of his hands; and something at his her like them to the callet of the point of etherfarner, and Mr. Bunfully and m\n",
            "f all the streets in the most of the come with into a more of the trestion.  It was a called in a large of my dinner to be a mreath before for the sack as ming in the into the same and some upon his hands away in the strong not dair, Mr Barked to him to as it with a little complece of poor hers to ar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3kqMUpV3eLh7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lower temperatures are less varied, choosing only the more probable outputs:"
      ]
    },
    {
      "metadata": {
        "id": "fn61avTLeLh-",
        "colab_type": "code",
        "outputId": "eb99648d-b52d-4689-9d45-821ccf3de5e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print(generate(decoder, 'T', predict_len=1000, temperature=0.2, cuda=device))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The arm so look of the strange of anything for the severed in a light and short of the doars of the returned with a started of the same of the ofference of his considered in the ward of the present to remark and the Clent dont to the near of a contracted in the same and face of the countense of his should be and a long street to him the suppresses of a state, and all the before the little of the country of the concertion with a preches of a monters of the fires of the course of the dark and some put to the lotter of the fore and far of the letter of the paces of the the into the good of the had all the one of the streat of the state of the come of the sire and congsed the concerning of her face of the sort of the present of the common to same her of her.  The ground of it is the strong some at the concertain of the concertainly was a state of the particular of the consion of the something of its of his fance of the course of a constance, and the sure of the same of the called to the sta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IEMX3C39eLiD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Higher temperatures more varied, choosing less probable outputs:"
      ]
    },
    {
      "metadata": {
        "id": "Bkh5R-xheLiD",
        "colab_type": "code",
        "outputId": "66499a52-6289-4b7f-c04f-faf1776d289b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print(generate(decoder, 'Th', predict_len=200, temperature=1.4, cuda=device))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This telreee, whost Pardonbi, creeply was? ited titicle.  Being his liked pauched thant, age.  No nught.  cob ma! readie wirkita,, daks, require To, Nandifme chil agrocivias debo, umall knals-cngard Do,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VddFLmwhSOq8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}